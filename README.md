<div align="center">

# üöÄ Autonomous Enterprise AI Decision System

[![CI/CD](https://github.com/OnlyAhad13/Autonomous-Enterprise-AI-Decision-System/actions/workflows/deploy.yml/badge.svg)](https://github.com/OnlyAhad13/Autonomous-Enterprise-AI-Decision-System/actions)
[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

**Production-grade ML platform with autonomous agent orchestration, real-time inference, and self-healing capabilities.**

[Quick Start](#-quick-start) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Features](#-features) ‚Ä¢ [Documentation](#-documentation) ‚Ä¢ [Contributing](#-contributing)

</div>

---

## üìã Overview

The **Autonomous Enterprise AI Decision System** is a comprehensive MLOps platform designed for production environments at scale. It combines real-time ML inference, autonomous agent-driven operations, and robust data pipelines into a unified system.

### Key Capabilities

| Capability | Description |
|------------|-------------|
| ü§ñ **Autonomous Agents** | LLM-orchestrated agents with ReAct reasoning, tool execution, and human-in-the-loop confirmation |
| üìä **Real-time Inference** | FastAPI prediction service with P99 < 200ms latency at 1000+ RPS |
| üîÑ **Auto-Retraining** | Drift-detection driven retraining with Airflow DAGs and MLflow promotion |
| üìö **RAG Pipeline** | Vector-based retrieval with FAISS/Milvus for contextual AI responses |
| üåä **Stream Processing** | Kafka + Spark Structured Streaming for real-time feature engineering |
| üìà **Full Observability** | Prometheus metrics, Grafana dashboards, and structured audit logging |

---

## üèó Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                              ENTERPRISE AI PLATFORM                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ   Data Sources   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Kafka Streams   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Spark Streaming ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  (APIs, DBs, S3) ‚îÇ    ‚îÇ  (events.raw.v1) ‚îÇ    ‚îÇ  (Transformation) ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                            ‚îÇ                     ‚îÇ
‚îÇ                                                            ‚ñº                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ   Feature Store  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ    Delta Lake    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ Feature Pipeline ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ     (Feast)      ‚îÇ    ‚îÇ   (Bronze‚ÜíGold)  ‚îÇ    ‚îÇ (Great Expectations)‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ           ‚îÇ                                                                      ‚îÇ
‚îÇ           ‚ñº                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ                        ML SERVICES                                 ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   Predict   ‚îÇ  ‚îÇ     RAG     ‚îÇ  ‚îÇ   Explain   ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   Service   ‚îÇ  ‚îÇ   Service   ‚îÇ  ‚îÇ   Service   ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  (FastAPI)  ‚îÇ  ‚îÇ  (FAISS)    ‚îÇ  ‚îÇ   (SHAP)    ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                    ‚îÇ                                             ‚îÇ
‚îÇ                                    ‚ñº                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ                      AUTONOMOUS AGENT LAYER                       ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Agent Core ‚îÇ  ‚îÇ    Tools    ‚îÇ  ‚îÇ  Prompts    ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (ReAct Loop)‚îÇ  ‚îÇ(MLflow,Kafka‚îÇ  ‚îÇ (Few-shot)  ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ Airflow,etc)‚îÇ  ‚îÇ             ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                    ‚îÇ                                             ‚îÇ
‚îÇ                                    ‚ñº                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ                    MLOPS & ORCHESTRATION                          ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   MLflow    ‚îÇ  ‚îÇ   Airflow   ‚îÇ  ‚îÇ Prometheus  ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  (Registry) ‚îÇ  ‚îÇ   (DAGs)    ‚îÇ  ‚îÇ  (Metrics)  ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚ú® Features

### ü§ñ Autonomous Agent System

- **ReAct Reasoning Loop**: Think ‚Üí Act ‚Üí Observe cycle with LLM orchestration
- **Tool Integration**: MLflow, Airflow, Kafka, Prometheus, Slack
- **Human-in-the-Loop**: Confirmation protocol for destructive actions
- **Retry Policy**: Exponential backoff with jitter and circuit breaker patterns

```python
from agents.agent_core import AgentCore

agent = AgentCore(llm_client=openai_client)
result = await agent.run_drift_check_and_retrain(
    model_name="forecasting-model",
    drift_threshold=0.1,
)
```

### üìä Prediction Service

- **High Performance**: P99 latency < 200ms, 1000+ RPS
- **Batch Processing**: CSV upload with async processing
- **Explainability**: SHAP/LIME feature importance
- **Auto-scaling**: HPA with CPU/memory-based scaling

```bash
# Single prediction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": {"age": 35, "income": 75000}}'

# Batch prediction
curl -X POST http://localhost:8000/batch_predict \
  -F "file=@data.csv"
```

### üîÑ Auto-Retraining Pipeline

- **Drift Detection**: Prometheus-based monitoring with configurable thresholds
- **Agent Decision**: LLM evaluates drift and recommends action
- **Conditional Training**: Spark or Python training based on data size
- **Auto-Promotion**: MLflow model staging with validation gates

```python
# Airflow DAG Flow
Drift Sensor ‚Üí Agent Decision ‚Üí Branch
                                  ‚îú‚îÄ‚îÄ Spark Training (large data)
                                  ‚îú‚îÄ‚îÄ Python Training (small data)
                                  ‚îî‚îÄ‚îÄ Skip (no drift)
                                        ‚Üì
                              Validation ‚Üí MLflow Promotion ‚Üí Slack Notification
```

### üìö RAG Pipeline

- **Document Ingestion**: Markdown, PDF, code file support
- **Vector Store**: FAISS (local) or Milvus (distributed)
- **Semantic Search**: Sentence Transformers embeddings
- **Context Retrieval**: Top-k relevant chunks for LLM context

```python
from services.rag.retriever import RAGRetriever

retriever = RAGRetriever()
response = retriever.query(
    "How does the model handle missing features?",
    top_k=5,
)
```

---

## üöÄ Quick Start

### Prerequisites

- Python 3.11+
- Docker & Docker Compose
- 8GB+ RAM

### Installation

```bash
# Clone repository
git clone https://github.com/OnlyAhad13/Autonomous-Enterprise-AI-Decision-System.git
cd Autonomous-Enterprise-AI-Decision-System

# Create virtual environment
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# Install dependencies
pip install -r requirements.txt

# Optional: Install development dependencies
pip install -e ".[dev]"
```

### Run Services

```bash
# Start all services (prediction, RAG, monitoring)
docker-compose -f docker-compose.predict.yml up -d
docker-compose -f docker-compose.monitoring.yml up -d

# Or run prediction service locally
cd services/predict
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

### Verify Installation

```bash
# Health check
curl http://localhost:8000/health

# Run tests
pytest tests/ -v --tb=short

# Run load tests
pip install locust
locust -f perf/locustfile.py --host=http://localhost:8000
```

---

## üìÅ Project Structure

```
‚îú‚îÄ‚îÄ agents/                    # Autonomous agent system
‚îÇ   ‚îú‚îÄ‚îÄ agent_core.py         # ReAct loop orchestration
‚îÇ   ‚îú‚îÄ‚îÄ tools/                # MLflow, Kafka, Airflow, Prometheus, Slack
‚îÇ   ‚îî‚îÄ‚îÄ prompts/              # System prompts, few-shot examples
‚îÇ
‚îú‚îÄ‚îÄ services/                  # Microservices
‚îÇ   ‚îú‚îÄ‚îÄ predict/              # FastAPI prediction service
‚îÇ   ‚îî‚îÄ‚îÄ rag/                  # RAG retrieval service
‚îÇ
‚îú‚îÄ‚îÄ ingest/                    # Data ingestion
‚îÇ   ‚îî‚îÄ‚îÄ dags/                 # Airflow DAGs (auto-retrain)
‚îÇ
‚îú‚îÄ‚îÄ spark_jobs/               # Spark streaming & batch
‚îÇ   ‚îî‚îÄ‚îÄ streaming_to_delta.py
‚îÇ
‚îú‚îÄ‚îÄ features/                  # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ feature_store.py      # Feast integration
‚îÇ   ‚îî‚îÄ‚îÄ transformers.py
‚îÇ
‚îú‚îÄ‚îÄ models/                    # Model training
‚îÇ   ‚îú‚îÄ‚îÄ train_forecast.py     # Prophet, LSTM, ETS
‚îÇ   ‚îî‚îÄ‚îÄ optuna_study.py       # Hyperparameter tuning
‚îÇ
‚îú‚îÄ‚îÄ mlflow_utils/             # MLflow utilities
‚îÇ   ‚îú‚îÄ‚îÄ auto_promote.py       # Model promotion
‚îÇ   ‚îî‚îÄ‚îÄ cli.py                # CLI tools
‚îÇ
‚îú‚îÄ‚îÄ conf/                      # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml        # Prometheus scrape config
‚îÇ   ‚îú‚îÄ‚îÄ alerting_rules.yml    # Alert rules
‚îÇ   ‚îî‚îÄ‚îÄ alertmanager.yml      # Alertmanager routing
‚îÇ
‚îú‚îÄ‚îÄ deploy/                    # Deployment
‚îÇ   ‚îî‚îÄ‚îÄ helm/                 # Helm charts (predict, rag)
‚îÇ
‚îú‚îÄ‚îÄ infra/                     # Infrastructure
‚îÇ   ‚îî‚îÄ‚îÄ terraform/            # EKS, MSK, RDS
‚îÇ
‚îú‚îÄ‚îÄ tests/                     # Test suites
‚îÇ   ‚îú‚îÄ‚îÄ e2e/                  # End-to-end tests
‚îÇ   ‚îî‚îÄ‚îÄ chaos/                # Chaos engineering
‚îÇ
‚îú‚îÄ‚îÄ perf/                      # Performance testing
‚îÇ   ‚îî‚îÄ‚îÄ locustfile.py         # Load tests
‚îÇ
‚îú‚îÄ‚îÄ docs/                      # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ SECURITY.md           # Security guide
‚îÇ   ‚îî‚îÄ‚îÄ COST_ESTIMATE.md      # AWS/GCP costs
‚îÇ
‚îî‚îÄ‚îÄ notebooks/                 # Jupyter notebooks
    ‚îú‚îÄ‚îÄ 01_EDA.ipynb
    ‚îú‚îÄ‚îÄ 02_baselines.ipynb
    ‚îî‚îÄ‚îÄ 04_rag_demo.ipynb
```

---

## üîß Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `MLFLOW_TRACKING_URI` | MLflow server URL | `http://localhost:5000` |
| `KAFKA_BOOTSTRAP_SERVERS` | Kafka brokers | `localhost:9092` |
| `OPENAI_API_KEY` | OpenAI API key | Required for agents |
| `SLACK_WEBHOOK_URL` | Slack notifications | Optional |
| `MODEL_NAME` | Model to serve | `forecasting-model` |

### Agent Policy (`conf/agent_policy.json`)

```json
{
  "drift": {
    "threshold": 0.1,
    "metric_name": "model_drift_score"
  },
  "actions": {
    "allowed": ["alert", "retrain", "promote", "rollback"],
    "require_confirmation": ["rollback"]
  },
  "safety": {
    "max_retrains_per_day": 3,
    "dry_run_mode": false
  }
}
```

---

## üìà Observability

### Metrics

Access Grafana dashboards at `http://localhost:3000` (admin/admin)

| Dashboard | Metrics |
|-----------|---------|
| ML Platform | P50/P95/P99 latency, error rate, throughput |
| Model Drift | Drift score, feature distributions |
| Agent Actions | Action counts, execution time |
| Infrastructure | CPU, memory, Kafka lag |

### Alerting

| Alert | Threshold | Severity |
|-------|-----------|----------|
| HighPredictionLatency | P99 > 500ms | Warning |
| ModelDriftDetected | drift > 0.1 | Warning |
| CriticalKafkaLag | lag > 100k | Critical |

---

## üß™ Testing

```bash
# Unit tests
pytest tests/ -v --cov=. --cov-report=html

# E2E tests (requires Docker)
docker-compose -f tests/e2e/docker-compose.e2e.yml up -d
E2E_MODE=true pytest tests/e2e/ -v

# Chaos tests
pytest tests/chaos/ -v

# Load tests
locust -f perf/locustfile.py --host=http://localhost:8000 \
  --users=100 --spawn-rate=10 --run-time=5m --headless
```

---

## üö¢ Deployment

### Kubernetes (Helm)

```bash
# Deploy prediction service
helm upgrade --install predict ./deploy/helm/predict \
  --namespace ml-services \
  --set image.tag=latest \
  --set replicaCount=3

# Deploy RAG service
helm upgrade --install rag ./deploy/helm/rag \
  --namespace ml-services
```

### Terraform (AWS)

```bash
cd infra/terraform
terraform init
terraform plan -var="environment=production"
terraform apply
```

### CI/CD (GitHub Actions)

The pipeline automatically:
1. Runs unit tests
2. Builds Docker images
3. Pushes to GHCR
4. Deploys to staging
5. Deploys to production (with approval)

---

## üí∞ Cost Estimates

| Environment | AWS | GCP |
|-------------|-----|-----|
| Staging | ~$320/month | ~$305/month |
| Production | ~$1,910/month | ~$1,590/month |

See [docs/COST_ESTIMATE.md](docs/COST_ESTIMATE.md) for detailed breakdown.

---

## üîí Security

- **Encryption**: TLS 1.3 in transit, AES-256 at rest (KMS)
- **RBAC**: Feature store, MLflow, Kubernetes access control
- **PII Masking**: Pseudonymization in pipelines
- **Audit Logging**: Structured logs for all agent actions

See [docs/SECURITY.md](docs/SECURITY.md) for security guidelines.

---

## üìö Documentation

| Document | Description |
|----------|-------------|
| [SECURITY.md](docs/SECURITY.md) | Security architecture |
| [COST_ESTIMATE.md](docs/COST_ESTIMATE.md) | Infrastructure costs |
| [infra/README.md](infra/README.md) | Operator guide |
| [conf/MONITORING.md](conf/MONITORING.md) | Observability setup |

---

## üõ† Development

### Setup

```bash
# Install pre-commit hooks
pip install pre-commit
pre-commit install

# Run formatters
black .
isort .

# Run linters
flake8 .
mypy .
```

### Adding a New Tool

```python
# agents/tools/tool_custom.py
from agents.tools.base import BaseTool, ToolResult

class CustomTool(BaseTool):
    def execute(self, **kwargs) -> ToolResult:
        # Implementation
        return ToolResult(success=True, data=result)
```

---

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Code Standards

- **Style**: Black (line length 100), isort
- **Types**: Full type annotations
- **Tests**: >80% coverage required
- **Docs**: Docstrings for public APIs

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file.

---

## üôè Acknowledgments

- [MLflow](https://mlflow.org/) - Model registry and tracking
- [Apache Kafka](https://kafka.apache.org/) - Event streaming
- [FastAPI](https://fastapi.tiangolo.com/) - API framework
- [Prometheus](https://prometheus.io/) - Monitoring

---

<div align="center">

**Built with ‚ù§Ô∏è for production ML at scale**

[‚¨Ü Back to Top](#-autonomous-enterprise-ai-decision-system)

</div>
