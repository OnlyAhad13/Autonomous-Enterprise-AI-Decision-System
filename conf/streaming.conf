# Streaming Pipeline Configuration
# HOCON format - loaded by pyhocon

streaming {
    # Application settings
    app {
        name = "StreamingToDelta"
        log_level = "INFO"
    }

    # Kafka source configuration
    kafka {
        source {
            bootstrap_servers = "localhost:9095"
            topic = "events.raw.v1"
            consumer_group = "streaming-to-delta"
            starting_offsets = "earliest"  # earliest | latest | specific offset
            max_offsets_per_trigger = 10000
            fail_on_data_loss = false
        }

        sink {
            bootstrap_servers = "localhost:9095"
            topic = "events.canonical.v1"
        }
    }

    # Delta Lake output configuration
    delta {
        output_path = "data/lake/delta/events/streaming"
        checkpoint_path = "data/lake/checkpoints/streaming-to-delta"
        partition_by = "dt"
        trigger_interval = "10 seconds"  # micro-batch interval
        
        # Compaction settings
        optimize_write = true
        auto_compact = true
    }

    # Geo lookup configuration
    geo {
        # Simple region mapping by lat/lon bounding boxes
        # Format: region_name -> [min_lat, max_lat, min_lon, max_lon]
        lookup_file = "conf/geo_regions.json"
        default_region = "UNKNOWN"
        cache_enabled = true
    }

    # Retry and backoff configuration
    retry {
        max_attempts = 5
        initial_delay_ms = 1000
        max_delay_ms = 60000
        backoff_multiplier = 2.0
    }

    # Processing settings
    processing {
        watermark_delay = "10 minutes"
        drop_duplicates = true
        dedupe_columns = ["id"]
    }
}
